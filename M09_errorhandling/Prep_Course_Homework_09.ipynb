{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suma(a,b):\n",
    "    return a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CajaNegraTest(unittest.TestCase):\n",
    "    \n",
    "    def test_suma_dos_positivos(self):\n",
    "        a = 5\n",
    "        b = 10\n",
    "        resultado = suma(a,b)\n",
    "        self.assertEqual(resultado,15)\n",
    "    \n",
    "    def test_suma_dos_negativos(self):\n",
    "        a = -10\n",
    "        b = -7\n",
    "        resultado = suma(a,b)\n",
    "        self.assertEqual(resultado,-17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x130478e4f50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)\n",
    "#test_suma_dos_positivos(__main__.CajaNegraTest)\n",
    "#test_suma_dos_negativos(__main__.CajaNegraTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_mayor(edad):\n",
    "    if edad >= 18:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruebaDeCristalTest(unittest.TestCase):\n",
    "    \n",
    "    def test_es_mayor(self):\n",
    "        edad = 20\n",
    "        resultado = es_mayor(20)\n",
    "        \n",
    "        self.assertEqual(resultado,True)\n",
    "    def test_es_menor(self):\n",
    "        edad = 15\n",
    "        resultado = es_mayor(edad)\n",
    "        self.assertEqual(resultado,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1304788bcd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)\n",
    "#test_es_mayor(__main__.PruebaDeCristalTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_elementos_lista(lista,divisor):\n",
    "    '''\n",
    "    Cada elemento de una lista es dividida por un divisor definido.\n",
    "    En caso de error de tipo ZeroDivisionError que\n",
    "    significa error al dividir en cero\n",
    "    la función devuelve la lista inicial\n",
    "    '''\n",
    "    try:\n",
    "        return [i/divisor for i in lista]\n",
    "    except ZeroDivisionError as e:\n",
    "        print(e)\n",
    "        return lista\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "lista = list(range(10))\n",
    "divisor = 0\n",
    "print(divide_elementos_lista(lista,divisor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo no existe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"archivo.txt\", \"r\") as f:\n",
    "        contenido = f.read()\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo no existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la clave no existe en el diccionario\n"
     ]
    }
   ],
   "source": [
    "paises = {\"Mexio\":\"mx\",\"Estados unidos\":\"us\",\"canada\":\"ca\"}\n",
    "try:\n",
    "    codigo = paises[\"argerntina\"]\n",
    "except KeyError:\n",
    "    print(\"la clave no existe en el diccionario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primera_letra(lista_palabras):\n",
    "    primeras_letras = []\n",
    "    for palabra in lista_palabras:\n",
    "        assert type(palabra) == str, f'{palabra} no es str'\n",
    "        assert len(palabra) > 0, 'No se permiten str vacíos'\n",
    "    primeras_letras.append(palabra[0])\n",
    "    return primeras_letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "No se permiten str vacíos",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lista \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhola\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgato\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m54\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprimera_letra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlista\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m, in \u001b[0;36mprimera_letra\u001b[1;34m(lista_palabras)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m palabra \u001b[38;5;129;01min\u001b[39;00m lista_palabras:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(palabra) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpalabra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m no es str\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(palabra) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo se permiten str vacíos\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m primeras_letras\u001b[38;5;241m.\u001b[39mappend(palabra[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m primeras_letras\n",
      "\u001b[1;31mAssertionError\u001b[0m: No se permiten str vacíos"
     ]
    }
   ],
   "source": [
    "lista = [\"hola\",\"gato\",\"54\",\"\"]\n",
    "primera_letra(lista)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'/C:/Users/Pablo/Desktop/Python-Prep/M09_errorhandling/herramientas.py') # Agrega la ruta al archivo 'herramientas.py' al sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herramientas as h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El programa arroja(raise) error por la linea definida en el metodo __init__ que especifica que si no es del tipo lista, arrojara un un error en forma de excepcion\n",
    "\n",
    "\"raise ValueError('Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = h.Herramientas(range(15))\n",
    "a = h.Herramientas([1,3,4,5,6,\"hola\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable a cuando se le pasa un range genera error porque no es del tipo lista, sin embargo al pasar uno de los parametros de la lista como un string, no genera error, aunque esto generara un error si se intenta realizar alguna de las operaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 15)\n",
      "<class 'range'>\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "a = h.Herramientas(list(range(15)))\n",
    "lista = range(15)\n",
    "print(lista)\n",
    "print(type(lista))\n",
    "lista = list(range(15))\n",
    "print(lista)\n",
    "print(type(lista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[273.15,\n",
       " 274.15,\n",
       " 275.15,\n",
       " 276.15,\n",
       " 277.15,\n",
       " 278.15,\n",
       " 279.15,\n",
       " 280.15,\n",
       " 281.15,\n",
       " 282.15,\n",
       " 283.15,\n",
       " 284.15,\n",
       " 285.15,\n",
       " 286.15,\n",
       " 287.15]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.conversion_grados(\"celsius\",\"kelvin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 24,\n",
       " 120,\n",
       " 720,\n",
       " 5040,\n",
       " 40320,\n",
       " 362880,\n",
       " 3628800,\n",
       " 39916800,\n",
       " 479001600,\n",
       " 6227020800,\n",
       " 87178291200]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.factorial()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Pablo\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib  #se importa el módulo importlib, el cual proporciona funciones para recargar (reload) módulos previamente importados. \n",
    "importlib.reload(h)  # la función reload() de importlib recargar el módulo herramientas (previamente importado y asignado a un alias h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[273.15,\n",
       " 274.15,\n",
       " 275.15,\n",
       " 276.15,\n",
       " 277.15,\n",
       " 278.15,\n",
       " 279.15,\n",
       " 280.15,\n",
       " 281.15,\n",
       " 282.15,\n",
       " 283.15,\n",
       " 284.15,\n",
       " 285.15,\n",
       " 286.15,\n",
       " 287.15]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.conversion_grados(\"celsius\",\"kelvin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest #se importa el módulo unittest,es un marco de trabajo integrado en Python para escribir y ejecutar pruebas unitarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentado paso a paso\n",
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Clase de prueba para la clase Herramientas del módulo 'h'.\n",
    "    Esta clase hereda de unittest.TestCase, lo que la convierte en una clase de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    def test_crear_objeto1(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido.\n",
    "        \"\"\"\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        # self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "        # Se utiliza assertRaises para verificar que al crear un objeto Herramientas con un parámetro inválido\n",
    "        # se genere una excepción de tipo ValueError. Se espera que el código en el bloque de prueba genere esta excepción.\n",
    "        # Si no se genera la excepción, el caso de prueba falla.\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro.\n",
    "        \"\"\"\n",
    "        param = [1, 2, 2, 5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "        # Se utiliza assertEqual para verificar que la lista almacenada en el objeto h1 de tipo Herramientas\n",
    "        # sea igual a a llista param proporcionada como parámetro al crear el objeto.\n",
    "        # Si las listas no son iguales, el caso de prueba falla.\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        \"\"\"\n",
    "        Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas.\n",
    "        \"\"\"\n",
    "        lis = [1, 2, 1, 3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)\n",
    "        # Se utiliza assertEqual para verificar que el valor de moda y la cantidad de repeticiones devueltos\n",
    "        # por el método valor_modal de la clase Herramientas sean iguales a los valores esperados almacenados en resultado.\n",
    "        # Si los valores no coinciden, el caso de prueba falla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido. ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro. ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas. ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x13047891b10>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Pablo\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "importlib.reload(h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de números enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHerramientas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pablo\\Desktop\\Python-Prep\\M09_errorhandling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(lista_numeros) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha creado una lista vacía. Se esperaba una lista de números enteros\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de números enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('algo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo agregado en el modulo de herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    def verifica_primo(self):\n",
    "        lista_primos = []\n",
    "        for i in self.lista:\n",
    "            if (self.__verifica_primo(i)):\n",
    "                lista_primos.append(True)\n",
    "            else:\n",
    "                lista_primos.append(False)\n",
    "        return lista_primos\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primos1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        primos = h1.verifica_primo()\n",
    "        primos_esperado = [True, True, False, False, True]\n",
    "        self.assertEqual(primos, primos_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Pablo\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido. ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro. ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas. ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x13047850950>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        def conversion_grados(self, origen, destino):\n",
    "        parametros_esperados = ['celsius','kelvin','farenheit']\n",
    "        lista_conversion = []\n",
    "        if str(origen) not in parametros_esperados:\n",
    "            print('Los parametros esperados son:', parametros_esperados)\n",
    "            return lista_conversion\n",
    "        if str(destino) not in parametros_esperados:\n",
    "            print('Los parametros esperados son:', parametros_esperados)\n",
    "            return lista_conversion\n",
    "        for i in self.lista:\n",
    "            lista_conversion.append(self.__conversion_grados(i, origen, destino))\n",
    "        return lista_conversion\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "    def test_verifica_conversion1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        grados = h1.conversion_grados('celsius','farenheit')\n",
    "        grados_esperado = [35.6, 37.4, 46.4, 50.0, 55.4]\n",
    "        self.assertEqual(grados, grados_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Pablo\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido. ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro. ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas. ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x13047ee59d0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    def factorial(self):\n",
    "        lista_factorial = []\n",
    "        for i in self.lista:\n",
    "            lista_factorial.append(self.__factorial(i))\n",
    "        return lista_factorial\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase4(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_factorial(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        factorial = h1.factorial()\n",
    "        factorial_esperado = [2, 6, 40320, 3628800, 6227020800]\n",
    "        self.assertEqual(factorial, factorial_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\Pablo\\\\Desktop\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_suma_dos_negativos (__main__.CajaNegraTest.test_suma_dos_negativos) ... ok\n",
      "test_suma_dos_positivos (__main__.CajaNegraTest.test_suma_dos_positivos) ... ok\n",
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con un parámetro inválido. ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2)\n",
      "Método de prueba para verificar el comportamiento al crear un objeto Herramientas con una lista válida como parámetro. ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "Método de prueba para verificar el comportamiento del método valor_modal de la clase Herramientas. ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "test_verifica_factorial (__main__.ProbandoMiClase4.test_verifica_factorial) ... ok\n",
      "test_es_mayor (__main__.PruebaDeCristalTest.test_es_mayor) ... ok\n",
      "test_es_menor (__main__.PruebaDeCristalTest.test_es_menor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x13046ebb790>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
